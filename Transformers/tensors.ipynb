{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = torch.zeros((3,4))\n",
    "mat[:,-1] = 1\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = torch.arange(0, 10)\n",
    "mat\n",
    "reversed(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9209, 0.8220, 0.5378],\n",
       "        [0.6088, 0.7381, 0.0000],\n",
       "        [0.6966, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = torch.rand((3, 3))\n",
    "\n",
    "mat[mat < 0.5] = 0\n",
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View vs Arrange\n",
    "\n",
    "View only works if the data contiguous in memory. This means that tensors is stored in row major order (like in c). When doing something like a transpose, what happens is that the data is not longer contiguous. This is so because the stride is changed instead. \n",
    "\n",
    "For example, \n",
    "\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "[1, 2, 3, 4, 5, 6] <- in memory\n",
    "x.stride() = (3, 1) #move 3 per row and 1 per column\n",
    "\n",
    "y = x.T\n",
    "y = [[1, 4],\n",
    "     [2, 5],\n",
    "     [3, 6]]\n",
    "\n",
    "â†’ [1, 2, 3, 4, 5, 6] It is stored the same way in memory still \n",
    "So, the stride for y is not y.stride() = (1, 3). \n",
    "\n",
    "This is not contiguous. Thus, we cannot use view.\n",
    "\n",
    "The alternative is using reshape. Reshape will make the tensor contigous and then it will return the view. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1713, 0.3745, 0.6764, 0.9429],\n",
      "         [0.3761, 0.2888, 0.6360, 0.0901],\n",
      "         [0.6549, 0.6014, 0.3872, 0.3306]],\n",
      "\n",
      "        [[0.5931, 0.1051, 0.4604, 0.2145],\n",
      "         [0.4054, 0.8765, 0.9626, 0.3082],\n",
      "         [0.9629, 0.2148, 0.9040, 0.8521]]])\n",
      "tensor([[0.6360, 0.0901],\n",
      "        [0.6549, 0.6014],\n",
      "        [0.3872, 0.3306]])\n",
      "tensor([[0.6360, 0.0901],\n",
      "        [0.6549, 0.6014],\n",
      "        [0.3872, 0.3306]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1713, 0.3745, 0.6764, 0.9429, 0.3761, 0.2888, 0.6360, 0.0901, 0.6549,\n",
       "        0.6014, 0.3872, 0.3306, 0.5931, 0.1051, 0.4604, 0.2145, 0.4054, 0.8765,\n",
       "        0.9626, 0.3082, 0.9629, 0.2148, 0.9040, 0.8521])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = torch.rand((2,3,4))\n",
    "print(mat)\n",
    "reshape = mat.reshape(4,3,2)[1, :, :]\n",
    "print(reshape)\n",
    "view = mat.view(4,3,2)[1, :, :]\n",
    "print(view)\n",
    "mat.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8251, 0.7888, 0.3800, 0.0900],\n",
      "        [0.3225, 0.2092, 0.1795, 0.3958],\n",
      "        [0.7340, 0.2396, 0.1373, 0.7040],\n",
      "        [0.1934, 0.9287, 0.3233, 0.2934]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2092, 0.1795],\n",
       "        [0.2396, 0.1373]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four = torch.rand((4,4))\n",
    "print(four)\n",
    "four[1:3, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[1., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The diemsion that is one is being virtually copied for the operation\n",
    "col = torch.ones((3,1)) # With broadcasting, (3,4)\n",
    "print(col)\n",
    "row = torch.ones((1,4)) # With broadcasting, (3,4)\n",
    "print(row)\n",
    "\n",
    "col + row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([[ 6],\n",
      "        [15],\n",
      "        [24]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667, 0.3333, 0.5000],\n",
       "        [0.2667, 0.3333, 0.4000],\n",
       "        [0.2917, 0.3333, 0.3750]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten = torch.arange(1,10).view(3,3)\n",
    "print(ten)\n",
    "# print(torch.softmax(ten.to(torch.float32), dim=1))\n",
    "print(torch.sum(ten, dim=1, keepdim=True)) #(3,1)\n",
    "ten = ten/torch.sum(ten, dim=1, keepdim=True)\n",
    "ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1,4)\n",
    "b = torch.arange(4,7)\n",
    "\n",
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.) tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "z = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "y = x**3 + 2*z\n",
    "\n",
    "y.backward() \n",
    "print(x.grad, z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8134, 2.4482, 2.3711, 1.8886],\n",
      "        [2.0594, 1.7317, 1.6445, 2.0376],\n",
      "        [2.4464, 2.0109, 1.8500, 2.4485]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((3, 4), requires_grad=True)\n",
    "\n",
    "def func(x):\n",
    "    return x**2 + torch.sin(x)\n",
    "\n",
    "y = func(x)\n",
    "temp = torch.ones_like(y) #Helps implement vector jacobian product. Explicitly when the output is not a scalar. \n",
    "y.backward(gradient=temp)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax test passed.\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=-1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7904],\n",
       "         [0.4538]],\n",
       "\n",
       "        [[1.3595],\n",
       "         [0.3426]],\n",
       "\n",
       "        [[0.5734],\n",
       "         [0.3826]]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1 = torch.rand((3, 2, 2))\n",
    "batch2 = torch.rand((3, 2, 1))\n",
    "\n",
    "torch.bmm(batch1, batch2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
